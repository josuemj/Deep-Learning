{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c51070d9",
   "metadata": {},
   "source": [
    "# Hoja de Trabajo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a6103",
   "metadata": {},
   "source": [
    "- Josue Marroquin 22397\n",
    "- Sebastian Huertas 22295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92e2602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b782a19",
   "metadata": {},
   "source": [
    "## Ejercicio 1 - Experimentación Práctica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f113b9bb",
   "metadata": {},
   "source": [
    "### Task 1 - Preparación del conjunto de datos\n",
    "Cargue el conjunto de datos de Iris utilizando bibliotecas como sklearn.datasets. Luego, divida el conjunto de datos\n",
    "en conjuntos de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb10bec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información del conjunto de datos:\n",
      "Forma del dataset: (150, 4)\n",
      "Número de características: 4\n",
      "Número de muestras: 150\n",
      "Clases: ['setosa' 'versicolor' 'virginica']\n",
      "Distribución de clases: [50 50 50]\n",
      "\n",
      "Primeras 5 filas del dataset:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target species  \n",
      "0       0  setosa  \n",
      "1       0  setosa  \n",
      "2       0  setosa  \n",
      "3       0  setosa  \n",
      "4       0  setosa  \n",
      "\n",
      "Conjunto de entrenamiento: 120 muestras\n",
      "Conjunto de validación: 30 muestras\n",
      "Distribución en entrenamiento: [40 40 40]\n",
      "Distribución en validación: [10 10 10]\n",
      "\n",
      "Datos preparados exitosamente para entrenamiento y validación\n",
      "Variables disponibles:\n",
      "- X_train, X_val: características originales\n",
      "- X_train_scaled, X_val_scaled: características estandarizadas\n",
      "- y_train, y_val: etiquetas\n",
      "- df: DataFrame completo con información descriptiva\n"
     ]
    }
   ],
   "source": [
    "# Cargar el conjunto de datos de Iris\n",
    "iris = load_iris()\n",
    "X = iris.data  # Características: sepal length, sepal width, petal length, petal width\n",
    "y = iris.target  # Etiquetas: 0=setosa, 1=versicolor, 2=virginica\n",
    "\n",
    "# Crear DataFrame para mejor visualización\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "df['species'] = df['target'].map({0: target_names[0], 1: target_names[1], 2: target_names[2]})\n",
    "\n",
    "print(\"Información del conjunto de datos:\")\n",
    "print(f\"Forma del dataset: {X.shape}\")\n",
    "print(f\"Número de características: {X.shape[1]}\")\n",
    "print(f\"Número de muestras: {X.shape[0]}\")\n",
    "print(f\"Clases: {target_names}\")\n",
    "print(f\"Distribución de clases: {np.bincount(y)}\")\n",
    "\n",
    "# Mostrar las primeras filas\n",
    "print(\"\\nPrimeras 5 filas del dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y validación (80% - 20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # Mantener la proporción de clases en ambos conjuntos\n",
    ")\n",
    "\n",
    "print(f\"\\nConjunto de entrenamiento: {X_train.shape[0]} muestras\")\n",
    "print(f\"Conjunto de validación: {X_val.shape[0]} muestras\")\n",
    "print(f\"Distribución en entrenamiento: {np.bincount(y_train)}\")\n",
    "print(f\"Distribución en validación: {np.bincount(y_val)}\")\n",
    "\n",
    "# Estandarizar las características (opcional pero recomendado para muchos algoritmos)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "print(\"\\nDatos preparados exitosamente para entrenamiento y validación\")\n",
    "print(\"Variables disponibles:\")\n",
    "print(\"- X_train, X_val: características originales\")\n",
    "print(\"- X_train_scaled, X_val_scaled: características estandarizadas\")\n",
    "print(\"- y_train, y_val: etiquetas\")\n",
    "print(\"- df: DataFrame completo con información descriptiva\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb6baa",
   "metadata": {},
   "source": [
    "### Task 2 - Arquitectura modelo\n",
    "Cree una red neuronal feedforward simple utilizando nn.Module de PyTorch. Luego, defina capa de entrada, capas\n",
    "ocultas y capa de salida. Después, elija las funciones de activación y el número de neuronas por capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f4a16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo utilizado: cpu\n",
      "Arquitectura del modelo:\n",
      "IrisClassifier(\n",
      "  (fc1): Linear(in_features=4, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (fc3): Linear(in_features=8, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "\n",
      "Número total de parámetros: 243\n",
      "Parámetros entrenables: 243\n",
      "\n",
      "Forma de los tensores:\n",
      "X_train: torch.Size([120, 4])\n",
      "X_val: torch.Size([30, 4])\n",
      "y_train: torch.Size([120])\n",
      "y_val: torch.Size([30])\n",
      "\n",
      "DataLoaders creados:\n",
      "Tamaño del lote: 16\n",
      "Número de lotes de entrenamiento: 8\n",
      "Número de lotes de validación: 2\n",
      "\n",
      "Configuración de entrenamiento:\n",
      "Función de pérdida: CrossEntropyLoss()\n",
      "Optimizador: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "Tasa de aprendizaje: 0.001\n",
      "\n",
      "Prueba del forward pass:\n",
      "Input shape: torch.Size([3, 4])\n",
      "Output shape: torch.Size([3, 3])\n",
      "Predictions: [1 1 1]\n",
      "Probabilities:\n",
      "[[0.31886908 0.41032174 0.27080914]\n",
      " [0.3610109  0.38580552 0.25318357]\n",
      " [0.3129109  0.3904168  0.29667222]]\n",
      "\n",
      "Modelo creado y configurado\n"
     ]
    }
   ],
   "source": [
    "# Task 2 - Arquitectura del modelo\n",
    "\n",
    "# Configurar dispositivo (GPU si está disponible, sino CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Dispositivo utilizado: {device}\")\n",
    "\n",
    "# Definir la arquitectura de la red neuronal feedforward\n",
    "class IrisClassifier(nn.Module):\n",
    "    def __init__(self, input_size=4, hidden_size1=16, hidden_size2=8, num_classes=3):\n",
    "        super(IrisClassifier, self).__init__()\n",
    "        \n",
    "        # Definir las capas\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)      # Capa de entrada: 4 -> 16\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)    # Primera capa oculta: 16 -> 8\n",
    "        self.fc3 = nn.Linear(hidden_size2, num_classes)     # Capa de salida: 8 -> 3\n",
    "        \n",
    "        # Capa de dropout para regularización\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass a través de la red\n",
    "        x = F.relu(self.fc1(x))         # Activación ReLU en primera capa\n",
    "        x = self.dropout(x)             # Aplicar dropout\n",
    "        x = F.relu(self.fc2(x))         # Activación ReLU en segunda capa\n",
    "        x = self.dropout(x)             # Aplicar dropout\n",
    "        x = self.fc3(x)                 # Capa de salida (sin activación, se aplica en loss)\n",
    "        return x\n",
    "\n",
    "# Crear instancia del modelo\n",
    "model = IrisClassifier(input_size=4, hidden_size1=16, hidden_size2=8, num_classes=3)\n",
    "model = model.to(device)\n",
    "\n",
    "# Mostrar la arquitectura del modelo\n",
    "print(\"Arquitectura del modelo:\")\n",
    "print(model)\n",
    "print(f\"\\nNúmero total de parámetros: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Parámetros entrenables: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "\n",
    "# Convertir datos de numpy a tensores de PyTorch\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled).to(device)\n",
    "X_val_tensor = torch.FloatTensor(X_val_scaled).to(device)\n",
    "y_train_tensor = torch.LongTensor(y_train).to(device)\n",
    "y_val_tensor = torch.LongTensor(y_val).to(device)\n",
    "\n",
    "print(f\"\\nForma de los tensores:\")\n",
    "print(f\"X_train: {X_train_tensor.shape}\")\n",
    "print(f\"X_val: {X_val_tensor.shape}\")\n",
    "print(f\"y_train: {y_train_tensor.shape}\")\n",
    "print(f\"y_val: {y_val_tensor.shape}\")\n",
    "\n",
    "# Crear DataLoaders para entrenamiento por lotes\n",
    "batch_size = 16\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"\\nDataLoaders creados:\")\n",
    "print(f\"Tamaño del lote: {batch_size}\")\n",
    "print(f\"Número de lotes de entrenamiento: {len(train_loader)}\")\n",
    "print(f\"Número de lotes de validación: {len(val_loader)}\")\n",
    "\n",
    "# Definir función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()  # Para clasificación multiclase\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "print(f\"\\nConfiguración de entrenamiento:\")\n",
    "print(f\"Función de pérdida: {criterion}\")\n",
    "print(f\"Optimizador: {optimizer}\")\n",
    "print(f\"Tasa de aprendizaje: 0.001\")\n",
    "\n",
    "# Función para probar el modelo con datos de ejemplo\n",
    "def test_forward_pass():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Tomar una muestra pequeña para probar\n",
    "        sample_input = X_train_tensor[:3]  # 3 muestras\n",
    "        output = model(sample_input)\n",
    "        probabilities = F.softmax(output, dim=1)\n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        \n",
    "        print(f\"\\nPrueba del forward pass:\")\n",
    "        print(f\"Input shape: {sample_input.shape}\")\n",
    "        print(f\"Output shape: {output.shape}\")\n",
    "        print(f\"Predictions: {predictions.cpu().numpy()}\")\n",
    "        print(f\"Probabilities:\\n{probabilities.cpu().numpy()}\")\n",
    "\n",
    "test_forward_pass()\n",
    "print(\"\\nModelo creado y configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2174b64e",
   "metadata": {},
   "source": [
    "### Task 3 - Funciones de Pérdida\n",
    "Utilice diferentes funciones de pérdida comunes como Cross-Entropy Loss y MSE para clasificación. Entrene el\n",
    "modelo con diferentes funciones de pérdida y registre las pérdidas de entrenamiento y test. Debe utilizar al menos 3\n",
    "diferentes funciones. Es decir, procure que su código sea capaz de parametrizar el uso de diferentes funciones de\n",
    "pérdida."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
